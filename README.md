# Analyzing Factuality in Counterspeech Generation Using Large Language Models
This mini-project aims to analyze the factuality of informative counterspeech generated by Large Language Models (LLMs) in response to hate speech. This study will focus on identifying the paths leading to factual inaccuracies and exploring intervention techniques to correct these inaccuracies, thereby improving the reliability and trustworthiness of LLM-generated counterspeech.

## Code 1: BART-based Counterspeech Generation Output Example
-> Input: “Women don't belong in leadership”.
->  Output: “There are a lot of reasons why women don't get elected”.
## Code 2: Factuality Analysis with Intervention Output Example
-> "Generate counterspeech for: Hater: I think that all Muslims are just sick and have a negative impact on Western society.\nHater: I don't want to accept that Islam is a religion of peace. Islam is a disease infecting the entire world.\nTarget: MUSLIMS\nCounterspeech: Islam is a religion of peace.“
-> "Generate counterspeech for: Hater: feminists are angry women\nHater: Women are subhuman, they don't have the brain to fight for themselves or for men.\nTarget: WOMEN\nCounterspeech: womensrights“
-> "Generate counterspeech for: Hater: Who the fuck are you? We are gutful sick of Vagina Misandrists trying to undermine White powerful makes, when they themselves are just envious, incompetent and useless.\nTarget: WOMEN\nCounterspeech: Who are you?"
